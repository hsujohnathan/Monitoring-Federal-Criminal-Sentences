---
title: "Lab 10 - Merging Data"
author: "Johnathan Hsu"
date: "November 2, 2017"
output:
  pdf_document: default
  html_document: default
---

Using your own dataset (which may include more than one table) carry out the following data cleaning steps. Knit together the PDF document and commit both the Lab 10 RMD file and the PDF document to Git. Push the changes to GitHub so both documents are visible in your public GitHub repository. 

1. For your poster project, do you have multiple tables you'd like to join together to create your complete dataset? If so, describe what each table represents. 

I do! They are data_95_96 (1995-1996)...all the way up to data_2015. They are individual sentences from each year.

2. What is/are your primary key(s)? If you have more than one table in your data, what is/are your foreign key(s)? Do your primary key(s) and foreign key(s) have the same name? If not, what does this mean for the way you need to specify potential data merges?

They all have the sae name. I do not have to specify anything. The keys have the same name. The data has been merged and you can see the work in "scripts/merge_data.r". 

3. If you do not need to merge tables to create your final dataset, create a new dataset from your original dataset with a `grouped_by()` summary of your choice. You will use this separate dataset to complete the following exercises. 

If you are merging separate tables as part of your data manipulation process, are your keys of the same data type? If not, what are the differences? Figure out the appropriate coercion process(es) and carry out the steps below. 

My keys are the same datatype after I swapped them out. If you look in merge_data.r I do a lot of the coersion and other necessary steps. Data is saved in num form so I could refer to the codebook as needed.

4. Perform each version of the mutating joins (don't forget to specify the `by` argument) and print the results to the console. Describe what each join did to your datasets and what the resulting data table looks like. For those joining two separate datasets, did any of these joins result in your desired final dataset? Why or why not?

I really don't need to join my datasets, I will practice though.

```{r}
# tidyverse
library(tidyverse)

# Spliting mtcars into to 2 parts
tibble_mtcars <- tbl_df(mtcars)
mtcars_1 <- tibble_mtcars[, 1:5]
mtcars_2 <- tibble_mtcars[, 6:10]
names <- rownames(mtcars)
mtcars_1 <- cbind(names, mtcars_1)
mtcars_2 <- cbind(names, mtcars_2)

# left_join 
left_join(mtcars_1, mtcars_2, by = "names")

# right_join
right_join(mtcars_1, mtcars_2, by = "names")

# inner_join (simulated by taking out Datsun 710)
mtcars_3 <- mtcars_1 %>%
  filter(names != "Datsun 710")

inner_join(mtcars_3, mtcars_2)

# full_join - we see that the missing variables for Datsun is last.
full_join(mtcars_3, mtcars_2)
```

5. Do the same thing with the filtering joins. What was the result? Give an example of a case in which a `semi_join()` or an `anti_join()` might be used with your primary dataset.

```{r}
# we see that semi_join excludes Datsun 710
semi_join(mtcars_3, mtcars_2, "names")


# we see that Datsun is the exception
anti_join(mtcars_2, mtcars_3, "names")
```

6. What happens when you apply the set operations joins to your tables? Are these functions useful for you for this project? Explain why or why not. If not, give an example in which one of them might be usefully applied to your data. 

```{r}
mtcars_frankenstein <- bind_cols(mtcars_1, mtcars_2)
```

Binding rows will be useful for my project, but since I'm working with mtcars, I will be binding them by columns.

7. If you have any reason to compare tables, apply `setequal()` below. What were the results? 

Not applicable.


8. What is the purpose of binding data and why might you need to take extra precaution when carrying out this specific form of data merging? If your data requires any binding, carry out the steps below and describe what was accomplished by your merge.

# I binded the data so we can match everything by year
```{r}
# importing clean data
setwd("/Users/hsujohnathan/monitoring-federal-criminal-sentences")
data_95_96 <- read.csv("clean_data/collapsed_data/95-96.csv")
data_96_97 <- read.csv("clean_data/collapsed_data/96-97.csv")
data_97_98 <- read.csv("clean_data/collapsed_data/97-98.csv")
data_1999 <- read.csv("clean_data/collapsed_data/1999.csv")
data_2000 <- read.csv("clean_data/collapsed_data/2000.csv")
data_2001 <- read.csv("clean_data/collapsed_data/2001.csv")
data_2002 <- read.csv("clean_data/collapsed_data/2002.csv")
data_2003 <- read.csv("clean_data/collapsed_data/2003.csv")
data_2004 <- read.csv("clean_data/collapsed_data/2004.csv")
data_2005 <- read.csv("clean_data/collapsed_data/2005.csv")
data_2006 <- read.csv("clean_data/collapsed_data/2006.csv") 
data_2007 <- read.csv("clean_data/collapsed_data/2007.csv") 
data_2008 <- read.csv("clean_data/collapsed_data/2008.csv") 
data_2009 <- read.csv("clean_data/collapsed_data/2009.csv") 
data_2010 <- read.csv("clean_data/collapsed_data/2010.csv") 
data_2011 <- read.csv("clean_data/collapsed_data/2011.csv") 
data_2012 <- read.csv("clean_data/collapsed_data/2012.csv") 
data_2013 <- read.csv("clean_data/collapsed_data/2013.csv") 
data_2014 <- read.csv("clean_data/collapsed_data/2014.csv") 
data_2015 <- read.csv("clean_data/collapsed_data/2015.csv") 

data_bind <- bind_rows(data_95_96, data_96_97, data_97_98, data_1999,
                       data_2000, data_2001, data_2002, data_2003,
                       data_2004, data_2005, data_2006, data_2007,
                       data_2008, data_2009, data_2010, data_2011,
                       data_2012, data_2013, data_2014, data_2015)
```

9. Do you need to merge multiple tables together using the same type of merge? If so, utilize the `reduce()` function from the `purrr` package to carry out the appropriate merge below. 

Not applicable

10. Are there any other steps you need to carry out to further clean, transform, or merge your data into one, final, tidy dataset? If so, describe what they are and carry them out below.

No. 

```{r}
tbl_df(head(data_bind))
```









